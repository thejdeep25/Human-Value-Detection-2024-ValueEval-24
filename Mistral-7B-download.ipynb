{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7705728,"sourceType":"datasetVersion","datasetId":4498785},{"sourceId":7928504,"sourceType":"datasetVersion","datasetId":4659866}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U transformers\n!pip install -q -U accelerate\n!pip install -q -U bitsandbytes\n!pip install datasets==2.15","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:23:11.055767Z","iopub.execute_input":"2024-03-25T10:23:11.056069Z","iopub.status.idle":"2024-03-25T10:24:16.379965Z","shell.execute_reply.started":"2024-03-25T10:23:11.056041Z","shell.execute_reply":"2024-03-25T10:24:16.378886Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting datasets==2.15\n  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (1.26.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (11.0.0)\nCollecting pyarrow-hotfix (from datasets==2.15)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nCollecting dill<0.3.8,>=0.3.0 (from datasets==2.15)\n  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (0.70.16)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (0.21.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15) (3.13.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.15) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15) (2024.2.2)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.15)\n  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.15) (1.16.0)\nDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, fsspec, dill, multiprocess, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.3.0\n    Uninstalling fsspec-2024.3.0:\n      Successfully uninstalled fsspec-2024.3.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.8\n    Uninstalling dill-0.3.8:\n      Successfully uninstalled dill-0.3.8\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.16\n    Uninstalling multiprocess-0.70.16:\n      Successfully uninstalled multiprocess-0.70.16\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ns3fs 2024.3.0 requires fsspec==2024.3.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.15.0 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 pyarrow-hotfix-0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:24:16.381995Z","iopub.execute_input":"2024-03-25T10:24:16.382300Z","iopub.status.idle":"2024-03-25T10:24:28.808067Z","shell.execute_reply.started":"2024-03-25T10:24:16.382272Z","shell.execute_reply":"2024-03-25T10:24:28.807046Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.39.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.28.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.2)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.21.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.10.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.10.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install scikit-multilearn\n!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:24:28.809367Z","iopub.execute_input":"2024-03-25T10:24:28.809649Z","iopub.status.idle":"2024-03-25T10:24:52.861336Z","shell.execute_reply.started":"2024-03-25T10:24:28.809622Z","shell.execute_reply":"2024-03-25T10:24:52.860327Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-multilearn in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.21.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport random\nimport functools\nimport csv\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom sklearn.metrics import f1_score\nfrom skmultilearn.model_selection import iterative_train_test_split\nfrom datasets import Dataset, DatasetDict\nfrom peft import (\n    LoraConfig,\n    prepare_model_for_kbit_training,\n    get_peft_model\n)\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:24:52.863987Z","iopub.execute_input":"2024-03-25T10:24:52.864308Z","iopub.status.idle":"2024-03-25T10:25:11.689903Z","shell.execute_reply.started":"2024-03-25T10:24:52.864279Z","shell.execute_reply":"2024-03-25T10:25:11.689049Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-03-25 10:25:03.869166: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-25 10:25:03.869279: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-25 10:25:04.005494: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:25:11.691035Z","iopub.execute_input":"2024-03-25T10:25:11.691606Z","iopub.status.idle":"2024-03-25T10:25:11.695914Z","shell.execute_reply.started":"2024-03-25T10:25:11.691577Z","shell.execute_reply":"2024-03-25T10:25:11.694896Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sentences_df = pd.read_csv('/kaggle/input/dl-original/training/sentences.tsv', sep='\\t')\nlabels_df = pd.read_csv('/kaggle/input/dl-original/training/labels.tsv', sep='\\t')","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:25:11.697113Z","iopub.execute_input":"2024-03-25T10:25:11.697462Z","iopub.status.idle":"2024-03-25T10:25:12.209520Z","shell.execute_reply.started":"2024-03-25T10:25:11.697430Z","shell.execute_reply":"2024-03-25T10:25:12.208486Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df1 = sentences_df\ndf2 = labels_df","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:25:12.210731Z","iopub.execute_input":"2024-03-25T10:25:12.211032Z","iopub.status.idle":"2024-03-25T10:25:12.215592Z","shell.execute_reply.started":"2024-03-25T10:25:12.211007Z","shell.execute_reply":"2024-03-25T10:25:12.214695Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nmerged_df = pd.merge(df1, df2, on=['Text-ID', 'Sentence-ID'])\nmerged_df\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:25:12.216905Z","iopub.execute_input":"2024-03-25T10:25:12.217193Z","iopub.status.idle":"2024-03-25T10:25:12.313373Z","shell.execute_reply.started":"2024-03-25T10:25:12.217170Z","shell.execute_reply":"2024-03-25T10:25:12.312497Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"        Text-ID  Sentence-ID  \\\n0        BG_002            1   \n1        BG_002            2   \n2        BG_002            3   \n3        BG_002            4   \n4        BG_002            5   \n...         ...          ...   \n40662  TR_M_022           12   \n40663  TR_M_022           13   \n40664  TR_M_022           14   \n40665  TR_M_022           15   \n40666  TR_M_022           16   \n\n                                                    Text  \\\n0      ДЪРЖАВАТА СРЕЩУ ЛОЗАН ПАНОВ ЗА СЪМНЕНИЯ, ЧЕ Е ...   \n1                                                    КВ.   \n2      М МОРСКО БУНГАЛО НА ЗАНИЖЕНИ ЦЕНИ Лавината от ...   \n3      Вече месеци наред той е обект на проверка за к...   \n4      Там от години прокуратурата се явява съдружник...   \n...                                                  ...   \n40662  Kolay kazanç sağlayan ve istihdam öngörmeyen r...   \n40663  Vergi tabana yayılacak, yoksul kesimin vergi y...   \n40664  Sosyal refahı artıracak destekleyici düzenleme...   \n40665  Yoksulluktan en fazla etkilenen eğitim düzeyi ...   \n40666  Temel ihtiyaçlar ile eğitim, sağlık ve sosyal ...   \n\n       Self-direction: thought attained  Self-direction: thought constrained  \\\n0                                   0.0                                  0.0   \n1                                   0.0                                  0.0   \n2                                   0.0                                  0.0   \n3                                   0.0                                  0.0   \n4                                   0.0                                  0.0   \n...                                 ...                                  ...   \n40662                               0.0                                  0.0   \n40663                               0.0                                  0.0   \n40664                               0.0                                  0.0   \n40665                               0.0                                  0.0   \n40666                               0.0                                  0.0   \n\n       Self-direction: action attained  Self-direction: action constrained  \\\n0                                  0.0                                 0.0   \n1                                  0.0                                 0.0   \n2                                  0.0                                 0.0   \n3                                  0.0                                 0.0   \n4                                  0.0                                 0.0   \n...                                ...                                 ...   \n40662                              0.0                                 0.0   \n40663                              0.0                                 0.0   \n40664                              0.0                                 0.0   \n40665                              1.0                                 0.0   \n40666                              0.0                                 0.0   \n\n       Stimulation attained  Stimulation constrained  Hedonism attained  ...  \\\n0                       0.0                      0.0                0.0  ...   \n1                       0.0                      0.0                0.0  ...   \n2                       0.0                      0.0                1.0  ...   \n3                       0.0                      0.0                0.0  ...   \n4                       0.0                      0.0                0.0  ...   \n...                     ...                      ...                ...  ...   \n40662                   0.5                      0.5                0.0  ...   \n40663                   0.0                      0.0                0.0  ...   \n40664                   0.0                      0.0                0.0  ...   \n40665                   0.0                      0.0                0.0  ...   \n40666                   0.0                      0.0                0.0  ...   \n\n       Benevolence: caring attained  Benevolence: caring constrained  \\\n0                               0.0                              0.0   \n1                               0.0                              0.0   \n2                               0.0                              0.0   \n3                               0.0                              0.0   \n4                               0.0                              0.0   \n...                             ...                              ...   \n40662                           0.0                              0.0   \n40663                           1.0                              0.0   \n40664                           0.0                              0.0   \n40665                           1.0                              0.0   \n40666                           1.0                              0.0   \n\n       Benevolence: dependability attained  \\\n0                                      0.0   \n1                                      0.0   \n2                                      0.0   \n3                                      0.0   \n4                                      0.0   \n...                                    ...   \n40662                                  0.0   \n40663                                  0.0   \n40664                                  0.0   \n40665                                  0.0   \n40666                                  0.0   \n\n       Benevolence: dependability constrained  Universalism: concern attained  \\\n0                                         0.0                             0.0   \n1                                         0.0                             0.0   \n2                                         0.0                             0.0   \n3                                         0.0                             0.0   \n4                                         0.0                             0.0   \n...                                       ...                             ...   \n40662                                     0.0                             0.0   \n40663                                     0.0                             0.0   \n40664                                     0.0                             0.0   \n40665                                     0.0                             0.0   \n40666                                     0.0                             0.0   \n\n       Universalism: concern constrained  Universalism: nature attained  \\\n0                                    0.0                            0.0   \n1                                    0.0                            0.0   \n2                                    0.0                            0.0   \n3                                    0.0                            0.0   \n4                                    0.0                            0.0   \n...                                  ...                            ...   \n40662                                0.0                            0.0   \n40663                                0.0                            0.0   \n40664                                0.0                            0.0   \n40665                                0.0                            0.0   \n40666                                0.0                            0.0   \n\n       Universalism: nature constrained  Universalism: tolerance attained  \\\n0                                   0.0                               0.0   \n1                                   0.0                               0.0   \n2                                   0.0                               0.0   \n3                                   0.0                               0.0   \n4                                   0.0                               0.0   \n...                                 ...                               ...   \n40662                               0.0                               0.0   \n40663                               0.0                               0.0   \n40664                               0.0                               0.0   \n40665                               0.0                               0.0   \n40666                               0.0                               0.0   \n\n       Universalism: tolerance constrained  \n0                                      0.0  \n1                                      0.0  \n2                                      0.0  \n3                                      0.0  \n4                                      0.0  \n...                                    ...  \n40662                                  0.0  \n40663                                  0.0  \n40664                                  0.0  \n40665                                  0.0  \n40666                                  0.0  \n\n[40667 rows x 41 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text-ID</th>\n      <th>Sentence-ID</th>\n      <th>Text</th>\n      <th>Self-direction: thought attained</th>\n      <th>Self-direction: thought constrained</th>\n      <th>Self-direction: action attained</th>\n      <th>Self-direction: action constrained</th>\n      <th>Stimulation attained</th>\n      <th>Stimulation constrained</th>\n      <th>Hedonism attained</th>\n      <th>...</th>\n      <th>Benevolence: caring attained</th>\n      <th>Benevolence: caring constrained</th>\n      <th>Benevolence: dependability attained</th>\n      <th>Benevolence: dependability constrained</th>\n      <th>Universalism: concern attained</th>\n      <th>Universalism: concern constrained</th>\n      <th>Universalism: nature attained</th>\n      <th>Universalism: nature constrained</th>\n      <th>Universalism: tolerance attained</th>\n      <th>Universalism: tolerance constrained</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BG_002</td>\n      <td>1</td>\n      <td>ДЪРЖАВАТА СРЕЩУ ЛОЗАН ПАНОВ ЗА СЪМНЕНИЯ, ЧЕ Е ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BG_002</td>\n      <td>2</td>\n      <td>КВ.</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BG_002</td>\n      <td>3</td>\n      <td>М МОРСКО БУНГАЛО НА ЗАНИЖЕНИ ЦЕНИ Лавината от ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BG_002</td>\n      <td>4</td>\n      <td>Вече месеци наред той е обект на проверка за к...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BG_002</td>\n      <td>5</td>\n      <td>Там от години прокуратурата се явява съдружник...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>40662</th>\n      <td>TR_M_022</td>\n      <td>12</td>\n      <td>Kolay kazanç sağlayan ve istihdam öngörmeyen r...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40663</th>\n      <td>TR_M_022</td>\n      <td>13</td>\n      <td>Vergi tabana yayılacak, yoksul kesimin vergi y...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40664</th>\n      <td>TR_M_022</td>\n      <td>14</td>\n      <td>Sosyal refahı artıracak destekleyici düzenleme...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40665</th>\n      <td>TR_M_022</td>\n      <td>15</td>\n      <td>Yoksulluktan en fazla etkilenen eğitim düzeyi ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40666</th>\n      <td>TR_M_022</td>\n      <td>16</td>\n      <td>Temel ihtiyaçlar ile eğitim, sağlık ve sosyal ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>40667 rows × 41 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"merged_df = merged_df[merged_df['Text-ID'].str.contains('EN')]","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:25:12.314720Z","iopub.execute_input":"2024-03-25T10:25:12.315082Z","iopub.status.idle":"2024-03-25T10:25:12.339406Z","shell.execute_reply.started":"2024-03-25T10:25:12.315049Z","shell.execute_reply":"2024-03-25T10:25:12.338589Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"merged_df = merged_df[~merged_df.isin(['0.5', '', pd.NA]).any(axis=1)]\nmerged_df = merged_df.drop(columns=merged_df.columns[:2])","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:25:12.343285Z","iopub.execute_input":"2024-03-25T10:25:12.343632Z","iopub.status.idle":"2024-03-25T10:25:12.398255Z","shell.execute_reply.started":"2024-03-25T10:25:12.343603Z","shell.execute_reply":"2024-03-25T10:25:12.397521Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"merged_df = merged_df[~(merged_df == 0.5).any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:25:12.399417Z","iopub.execute_input":"2024-03-25T10:25:12.399750Z","iopub.status.idle":"2024-03-25T10:25:12.407245Z","shell.execute_reply.started":"2024-03-25T10:25:12.399719Z","shell.execute_reply":"2024-03-25T10:25:12.406446Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X = merged_df.iloc[:, :1]  # Assuming the first two columns are features\nY = merged_df.iloc[:, 1:]  # Assuming the rest of the columns are labels\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:25:12.408461Z","iopub.execute_input":"2024-03-25T10:25:12.408750Z","iopub.status.idle":"2024-03-25T10:25:12.416019Z","shell.execute_reply.started":"2024-03-25T10:25:12.408725Z","shell.execute_reply":"2024-03-25T10:25:12.415313Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming Y is your DataFrame\nfor column in Y.columns:\n    unique_values = Y[column].unique()\n    print(f\"Unique values in column '{column}':\")\n    print(unique_values)\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:25:12.417045Z","iopub.execute_input":"2024-03-25T10:25:12.417348Z","iopub.status.idle":"2024-03-25T10:25:12.438085Z","shell.execute_reply.started":"2024-03-25T10:25:12.417318Z","shell.execute_reply":"2024-03-25T10:25:12.437226Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Unique values in column 'Self-direction: thought attained':\n[0. 1.]\n\nUnique values in column 'Self-direction: thought constrained':\n[0. 1.]\n\nUnique values in column 'Self-direction: action attained':\n[0. 1.]\n\nUnique values in column 'Self-direction: action constrained':\n[0. 1.]\n\nUnique values in column 'Stimulation attained':\n[0. 1.]\n\nUnique values in column 'Stimulation constrained':\n[0. 1.]\n\nUnique values in column 'Hedonism attained':\n[0. 1.]\n\nUnique values in column 'Hedonism constrained':\n[0. 1.]\n\nUnique values in column 'Achievement attained':\n[0. 1.]\n\nUnique values in column 'Achievement constrained':\n[0. 1.]\n\nUnique values in column 'Power: dominance attained':\n[0. 1.]\n\nUnique values in column 'Power: dominance constrained':\n[0. 1.]\n\nUnique values in column 'Power: resources attained':\n[0. 1.]\n\nUnique values in column 'Power: resources constrained':\n[0. 1.]\n\nUnique values in column 'Face attained':\n[0. 1.]\n\nUnique values in column 'Face constrained':\n[0. 1.]\n\nUnique values in column 'Security: personal attained':\n[0. 1.]\n\nUnique values in column 'Security: personal constrained':\n[0. 1.]\n\nUnique values in column 'Security: societal attained':\n[0. 1.]\n\nUnique values in column 'Security: societal constrained':\n[0. 1.]\n\nUnique values in column 'Tradition attained':\n[0. 1.]\n\nUnique values in column 'Tradition constrained':\n[1. 0.]\n\nUnique values in column 'Conformity: rules attained':\n[0. 1.]\n\nUnique values in column 'Conformity: rules constrained':\n[0. 1.]\n\nUnique values in column 'Conformity: interpersonal attained':\n[0. 1.]\n\nUnique values in column 'Conformity: interpersonal constrained':\n[0. 1.]\n\nUnique values in column 'Humility attained':\n[0. 1.]\n\nUnique values in column 'Humility constrained':\n[0. 1.]\n\nUnique values in column 'Benevolence: caring attained':\n[0. 1.]\n\nUnique values in column 'Benevolence: caring constrained':\n[0. 1.]\n\nUnique values in column 'Benevolence: dependability attained':\n[0. 1.]\n\nUnique values in column 'Benevolence: dependability constrained':\n[0. 1.]\n\nUnique values in column 'Universalism: concern attained':\n[0. 1.]\n\nUnique values in column 'Universalism: concern constrained':\n[0. 1.]\n\nUnique values in column 'Universalism: nature attained':\n[0. 1.]\n\nUnique values in column 'Universalism: nature constrained':\n[0. 1.]\n\nUnique values in column 'Universalism: tolerance attained':\n[0. 1.]\n\nUnique values in column 'Universalism: tolerance constrained':\n[0. 1.]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ncombined_data = pd.DataFrame({\n    'Text': X['Text'],\n    'labels': Y.apply(list, axis=1)\n})\ncombined_data","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:25:12.439514Z","iopub.execute_input":"2024-03-25T10:25:12.439780Z","iopub.status.idle":"2024-03-25T10:25:12.548119Z","shell.execute_reply.started":"2024-03-25T10:25:12.439759Z","shell.execute_reply":"2024-03-25T10:25:12.547147Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                    Text  \\\n12765  Hispanic Voters Are Losing Faith In The Democr...   \n12766  The support of Hispanic voters at the midterms...   \n12767  U.S. President Joe Biden speaks to employees a...   \n12768  (Julie Bennett/Getty Images) According to a Qu...   \n12769  This marks the lowest approval rating of any d...   \n...                                                  ...   \n19004  This will reduce America's vulnerability to en...   \n19005  Direct Provision was only ever intended to be ...   \n19011  Legislate to provide Irish born children norma...   \n19013  Extend the ombudsman’s jurisdiction to the app...   \n19014  Investigate appropriate systems to allow those...   \n\n                                                  labels  \n12765  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n12766  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n12767  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n12768  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n12769  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n...                                                  ...  \n19004  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n19005  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n19011  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n19013  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n19014  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n\n[6181 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12765</th>\n      <td>Hispanic Voters Are Losing Faith In The Democr...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>12766</th>\n      <td>The support of Hispanic voters at the midterms...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>12767</th>\n      <td>U.S. President Joe Biden speaks to employees a...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>12768</th>\n      <td>(Julie Bennett/Getty Images) According to a Qu...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>12769</th>\n      <td>This marks the lowest approval rating of any d...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19004</th>\n      <td>This will reduce America's vulnerability to en...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>19005</th>\n      <td>Direct Provision was only ever intended to be ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>19011</th>\n      <td>Legislate to provide Irish born children norma...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>19013</th>\n      <td>Extend the ombudsman’s jurisdiction to the app...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>19014</th>\n      <td>Investigate appropriate systems to allow those...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>6181 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport random\nfrom skmultilearn.model_selection import iterative_train_test_split\nfrom datasets import Dataset, DatasetDict\n\n# Set random seed\nrandom.seed(0)\n\n# Shuffle data\ncombined_data = combined_data.sample(frac=1, random_state=0).reset_index(drop=True)\n\n# Extract 'Text' and 'labels' columns\ntext = combined_data['Text'].tolist()\nlabels = combined_data['labels'].tolist()\n\n# Create label weights\nlabels = np.array(labels)\nlabel_weights = 1 - labels.sum(axis=0) / labels.sum()\n\n# Stratified train-test split for multilabel dataset\nrow_ids = np.arange(len(labels))\ntrain_idx, y_train, val_idx, y_val = iterative_train_test_split(row_ids[:, np.newaxis], labels, test_size=0.1)\nx_train = [text[i] for i in train_idx.flatten()]\nx_val = [text[i] for i in val_idx.flatten()]\n\n# Create Hugging Face dataset\nds = DatasetDict({\n    'train': Dataset.from_dict({'text': x_train, 'labels': y_train}),\n    'val': Dataset.from_dict({'text': x_val, 'labels': y_val})\n})\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-03-25T10:25:12.549373Z","iopub.execute_input":"2024-03-25T10:25:12.549707Z","iopub.status.idle":"2024-03-25T10:25:12.800064Z","shell.execute_reply.started":"2024-03-25T10:25:12.549684Z","shell.execute_reply":"2024-03-25T10:25:12.799349Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model name\nmodel_name = 'mistralai/Mistral-7B-v0.1'\n\n# preprocess dataset with tokenizer\ndef tokenize_examples(examples, tokenizer):\n    tokenized_inputs = tokenizer(examples['text'])\n    tokenized_inputs['labels'] = examples['labels']\n    return tokenized_inputs\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\ntokenized_ds = ds.map(functools.partial(tokenize_examples, tokenizer=tokenizer), batched=True)\ntokenized_ds = tokenized_ds.with_format('torch')\n\n# qunatization config\n# qunatization config\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # enable 4-bit quantization\n    bnb_4bit_quant_type='nf4',  # information theoretically optimal dtype for normally distributed weights\n    bnb_4bit_use_double_quant=True,  # quantize quantized weights //insert xzibit meme\n    #bnb_4bit_compute_dtype=torch.bfloat16,  # optimized fp format for ML\n    \n)\n\n\n# lora config\nlora_config = LoraConfig(\n    r = 16, # the dimension of the low-rank matrices\n    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n    lora_dropout = 0.05, # dropout probability of the LoRA layers\n    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n    task_type = 'SEQ_CLS'\n)\n\nlabels_array = np.array(labels)\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    quantization_config=quantization_config,\n    num_labels=labels_array.shape[1]  # Access the shape attribute of labels_array\n)\n\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)\nmodel.config.pad_token_id = tokenizer.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:25:12.801096Z","iopub.execute_input":"2024-03-25T10:25:12.801383Z","iopub.status.idle":"2024-03-25T10:26:44.103900Z","shell.execute_reply.started":"2024-03-25T10:25:12.801358Z","shell.execute_reply":"2024-03-25T10:26:44.102875Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc98ad3f7a244d479f0714b810b7e229"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1b56b8e8b5149efb719b1e4e6228e4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cf1269d5ea9469191f43a8270dae168"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"577b8082f9cd4332ad6fea06e701caa5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5562 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d7642ba1c6c42869cf27d831a4e3a1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/619 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ce84a4d0364477482604f9ef1f11654"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56f686fefc754494894c315b44b477f2"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"638a87259a7a43129f8bcd499f394622"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a08126b72624ad9b680ea27ec426ea4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c01f34c4bd44c898688f78bce76779c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b99ef9adb17473682ac28d2f698151f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e56008e696d747b28819c45a701cc92d"}},"metadata":{}},{"name":"stderr","text":"Some weights of MistralForSequenceClassification were not initialized from the model checkpoint at mistralai/Mistral-7B-v0.1 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# define custom batch preprocessor\ndef collate_fn(batch, tokenizer):\n    dict_keys = ['input_ids', 'attention_mask', 'labels']\n    d = {k: [dic[k] for dic in batch] for k in dict_keys}\n    d['input_ids'] = torch.nn.utils.rnn.pad_sequence(\n        d['input_ids'], batch_first=True, padding_value=tokenizer.pad_token_id\n    )\n    d['attention_mask'] = torch.nn.utils.rnn.pad_sequence(\n        d['attention_mask'], batch_first=True, padding_value=0\n    )\n    d['labels'] = torch.stack(d['labels'])\n    return d\n\n# define which metrics to compute for evaluation\ndef compute_metrics(p):\n    predictions, labels = p\n    f1_micro = f1_score(labels, predictions > 0, average = 'micro')\n    f1_macro = f1_score(labels, predictions > 0, average = 'macro')\n    f1_weighted = f1_score(labels, predictions > 0, average = 'weighted')\n    return {\n        'f1_micro': f1_micro,\n        'f1_macro': f1_macro,\n        'f1_weighted': f1_weighted\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T14:40:20.921686Z","iopub.execute_input":"2024-03-25T14:40:20.922345Z","iopub.status.idle":"2024-03-25T14:40:20.931559Z","shell.execute_reply.started":"2024-03-25T14:40:20.922310Z","shell.execute_reply":"2024-03-25T14:40:20.930490Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# create custom trainer class to be able to pass label weights and calculate mutilabel loss\nclass CustomTrainer(Trainer):\n\n    def __init__(self, label_weights, **kwargs):\n        super().__init__(**kwargs)\n        self.label_weights = label_weights\n    \n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        \n        # forward pass\n        outputs = model(**inputs)\n        logits = outputs.get(\"logits\")\n        \n        # compute custom loss\n        loss = F.binary_cross_entropy_with_logits(logits, labels.to(torch.float32), pos_weight=self.label_weights)\n        return (loss, outputs) if return_outputs else loss\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:26:44.117141Z","iopub.execute_input":"2024-03-25T10:26:44.117781Z","iopub.status.idle":"2024-03-25T10:26:44.433621Z","shell.execute_reply.started":"2024-03-25T10:26:44.117748Z","shell.execute_reply":"2024-03-25T10:26:44.432562Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import warnings\nimport functools\nimport torch\n\n# Suppress the deprecation warning\nwarnings.filterwarnings(\"ignore\", message=\"In the future `np.object` will be defined as the corresponding NumPy scalar.\")\n\n# Define training args\ntraining_args = TrainingArguments(\n    output_dir='multilabel_classification',\n    learning_rate=1e-4,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True\n)\n\n# Train\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_ds['train'],\n    eval_dataset=tokenized_ds['val'],\n    tokenizer=tokenizer,\n    data_collator=functools.partial(collate_fn, tokenizer=tokenizer),\n    compute_metrics=compute_metrics,\n    label_weights=torch.tensor(label_weights, device=model.device)\n)\n\ntrainer.train()\n\n# Save model\npeft_model_id = 'multilabel_mistral'\ntrainer.model.save_pretrained(peft_model_id)\ntokenizer.save_pretrained(peft_model_id)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T10:26:44.434849Z","iopub.execute_input":"2024-03-25T10:26:44.435137Z","iopub.status.idle":"2024-03-25T14:08:02.075637Z","shell.execute_reply.started":"2024-03-25T10:26:44.435113Z","shell.execute_reply":"2024-03-25T14:08:02.074631Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240325_102706-0uxzbz3x</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/somu_cse/huggingface/runs/0uxzbz3x' target=\"_blank\">astral-bee-42</a></strong> to <a href='https://wandb.ai/somu_cse/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/somu_cse/huggingface' target=\"_blank\">https://wandb.ai/somu_cse/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/somu_cse/huggingface/runs/0uxzbz3x' target=\"_blank\">https://wandb.ai/somu_cse/huggingface/runs/0uxzbz3x</a>"},"metadata":{}},{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3480' max='3480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3480/3480 3:40:18, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n      <th>F1 Weighted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.099700</td>\n      <td>0.038262</td>\n      <td>0.040201</td>\n      <td>0.009840</td>\n      <td>0.035639</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.037100</td>\n      <td>0.031166</td>\n      <td>0.173160</td>\n      <td>0.057331</td>\n      <td>0.137506</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.019900</td>\n      <td>0.034563</td>\n      <td>0.309677</td>\n      <td>0.189530</td>\n      <td>0.269213</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.009400</td>\n      <td>0.042407</td>\n      <td>0.271186</td>\n      <td>0.138620</td>\n      <td>0.251159</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.003700</td>\n      <td>0.050969</td>\n      <td>0.293907</td>\n      <td>0.155873</td>\n      <td>0.275073</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"('multilabel_mistral/tokenizer_config.json',\n 'multilabel_mistral/special_tokens_map.json',\n 'multilabel_mistral/tokenizer.model',\n 'multilabel_mistral/added_tokens.json',\n 'multilabel_mistral/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"# sentences_df = pd.read_csv('/kaggle/input/dl-original/validation/sentences.tsv', sep='\\t')\n# labels_df = pd.read_csv('/kaggle/input/dl-original/validation/labels.tsv', sep='\\t')\n# df1 = sentences_df\n# df2 = labels_df\n# import pandas as pd\n# merged_df = pd.merge(df1, df2, on=['Text-ID', 'Sentence-ID'])\n# merged_df = merged_df[merged_df['Text-ID'].str.contains('EN')]\n# merged_df = merged_df[~merged_df.isin(['0.5', '', pd.NA]).any(axis=1)]\n# merged_df = merged_df.drop(columns=merged_df.columns[:2])\n# merged_df = merged_df[~(merged_df == 0.5).any(axis=1)]\n# X = merged_df.iloc[:, :1]  # Assuming the first two columns are features\n# Y = merged_df.iloc[:, 1:]  # Assuming the rest of the columns are labels\n# import pandas as pd\n# combined_data = pd.DataFrame({\n#     'Text': X['Text'],\n#     'labels': Y.apply(list, axis=1)\n# })","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\ntest_text = combined_data['Text'].tolist()\ntest_labels = combined_data['labels'].tolist()\n\n# Create Hugging Face test dataset\ntest_dataset = Dataset.from_dict({'text': test_text, 'labels': test_labels})\n\n# Tokenize the test examples\ntokenized_test_dataset = test_dataset.map(\n    lambda example: tokenizer(example['text']),\n    batched=True,\n)\n\n# Set the format to 'torch'\ntokenized_test_dataset.set_format('torch')\n\n# Test the model\npredictions = trainer.predict(tokenized_test_dataset)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T14:40:46.327140Z","iopub.execute_input":"2024-03-25T14:40:46.328032Z","iopub.status.idle":"2024-03-25T14:56:05.054988Z","shell.execute_reply.started":"2024-03-25T14:40:46.327999Z","shell.execute_reply":"2024-03-25T14:56:05.053154Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6181 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b386da54d054e82b10dd2fc15735a7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[46], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m predictions \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(tokenized_test_dataset)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Convert logits to predicted labels\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Add predicted labels to the DataFrame\u001b[39;00m\n\u001b[1;32m     25\u001b[0m combined_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_Labels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predicted_labels\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'int'"],"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'int'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions.predictions","metadata":{"execution":{"iopub.status.busy":"2024-03-25T14:56:44.760988Z","iopub.execute_input":"2024-03-25T14:56:44.761630Z","iopub.status.idle":"2024-03-25T14:56:44.769939Z","shell.execute_reply.started":"2024-03-25T14:56:44.761595Z","shell.execute_reply":"2024-03-25T14:56:44.768754Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"array([[ -8.450628 ,  -8.149525 ,  -1.4913938, ...,  -9.419984 ,\n         -6.2623763,  -5.943224 ],\n       [ -8.868511 , -10.012003 ,  -6.248975 , ...,  -9.882385 ,\n         -8.968958 ,  -8.20541  ],\n       [ -7.0834837,  -6.1419477,  -5.6137886, ...,  -9.381815 ,\n         -5.359112 ,  -6.5315905],\n       ...,\n       [ -5.7685604, -11.083858 ,  -4.7825737, ..., -12.263563 ,\n         -8.066369 ,  -9.830065 ],\n       [ -6.5054493,  -6.152956 ,  -2.2597399, ...,  -7.725224 ,\n         -5.1426134,  -3.0596461],\n       [ -7.9736423,  -7.6082916,  -3.651897 , ...,  -8.719881 ,\n         -5.507146 ,  -6.513278 ]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"# Convert logits to predicted labels\npredicted_labels = (predictions.predictions > 0).astype(np.int32).tolist()\n\n\n# Add predicted labels to the DataFrame\ncombined_data['Predicted_Labels'] = predicted_labels\n\n# Display the DataFrame with predicted labels\nprint(combined_data.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-25T14:57:33.102058Z","iopub.execute_input":"2024-03-25T14:57:33.102884Z","iopub.status.idle":"2024-03-25T14:57:33.128418Z","shell.execute_reply.started":"2024-03-25T14:57:33.102850Z","shell.execute_reply":"2024-03-25T14:57:33.127340Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"                                                Text  \\\n0                                  End the mandates!   \n1  However, the DHS expert stressed that emerging...   \n2  Ms Ní Sheaghdha told Mary Wilson on this eveni...   \n3  The men’s team has agreed to a pay cut to ensu...   \n4  Barr was serving as attorney general at the time.   \n\n                                              labels  \\\n0  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n\n                                    Predicted_Labels  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\n# Assuming true_labels and predicted_labels are DataFrame columns\ntrue_labels = combined_data['labels']\npredicted_labels = combined_data['Predicted_Labels']\nTL = []\nPL = []\nfor i in true_labels:\n    sub = []\n    for j in i:\n        sub.append(j)\n    TL.append(sub)\nfor i in predicted_labels:\n    sub = []\n    for j in i:\n        sub.append(j)\n    PL.append(sub)\n\n\n\nlabel_namesS = []\nfor i in range(0,38):\n  label_namesS.append(str(i))\nclassification_rep = classification_report(TL,PL, target_names=label_namesS)\nprint(classification_rep)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:10:32.263783Z","iopub.execute_input":"2024-03-25T15:10:32.264151Z","iopub.status.idle":"2024-03-25T15:10:32.461555Z","shell.execute_reply.started":"2024-03-25T15:10:32.264120Z","shell.execute_reply":"2024-03-25T15:10:32.460565Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        14\n           1       0.00      0.00      0.00        12\n           2       1.00      0.03      0.06       103\n           3       0.00      0.00      0.00        60\n           4       0.00      0.00      0.00        22\n           5       0.00      0.00      0.00         4\n           6       1.00      0.11      0.20        18\n           7       0.00      0.00      0.00         2\n           8       0.71      0.62      0.66       174\n           9       1.00      0.14      0.25        92\n          10       0.00      0.00      0.00        84\n          11       0.00      0.00      0.00        18\n          12       1.00      0.07      0.13        70\n          13       0.00      0.00      0.00        25\n          14       0.00      0.00      0.00        15\n          15       1.00      0.06      0.12        31\n          16       1.00      0.06      0.12        31\n          17       0.00      0.00      0.00        52\n          18       0.74      0.42      0.54       131\n          19       0.81      0.42      0.55       201\n          20       1.00      0.28      0.43        36\n          21       0.00      0.00      0.00        13\n          22       1.00      0.09      0.16       125\n          23       1.00      0.13      0.23       106\n          24       0.00      0.00      0.00        24\n          25       1.00      0.04      0.08        76\n          26       0.00      0.00      0.00        22\n          27       0.00      0.00      0.00         4\n          28       0.00      0.00      0.00        34\n          29       1.00      0.20      0.33         5\n          30       0.00      0.00      0.00        28\n          31       0.00      0.00      0.00        11\n          32       1.00      0.22      0.36       143\n          33       1.00      0.18      0.30        56\n          34       1.00      0.40      0.58        42\n          35       0.00      0.00      0.00        17\n          36       0.00      0.00      0.00        16\n          37       0.86      0.42      0.56        43\n\n   micro avg       0.82      0.20      0.32      1960\n   macro avg       0.45      0.10      0.15      1960\nweighted avg       0.69      0.20      0.27      1960\n samples avg       0.06      0.06      0.06      1960\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\n# Assuming true_labels and predicted_labels are DataFrame columns\ntrue_labels = combined_data['labels']\npredicted_labels = combined_data['Predicted_Labels']\nTL = []\nPL = []\nfor i in true_labels:\n    sub = []\n    for j in range(0,len(i),2):\n        a = i[j]\n        b = i[j+1]\n\n        if a + b >= 0.5 :\n\n            sub.append(1)\n\n        else :\n            sub.append(0)\n    TL.append(sub)\n    \nfor i in predicted_labels:\n    sub = []\n    for j in range(0,len(i),2):\n        a = i[j]\n        b = i[j+1]\n\n        if a + b >= 0.5 :\n\n            sub.append(1)\n\n        else :\n            sub.append(0)\n    PL.append(sub)\n\n\n\nlabel_namesS = []\nfor i in range(0,19):\n  label_namesS.append(str(i))\nclassification_rep = classification_report(TL,PL, target_names=label_namesS)\nprint(classification_rep)","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:13:53.427718Z","iopub.execute_input":"2024-03-25T15:13:53.428377Z","iopub.status.idle":"2024-03-25T15:13:53.647043Z","shell.execute_reply.started":"2024-03-25T15:13:53.428344Z","shell.execute_reply":"2024-03-25T15:13:53.645915Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        26\n           1       1.00      0.02      0.04       163\n           2       0.00      0.00      0.00        26\n           3       1.00      0.10      0.18        20\n           4       0.73      0.46      0.56       266\n           5       0.00      0.00      0.00       102\n           6       1.00      0.05      0.10        95\n           7       1.00      0.04      0.08        46\n           8       1.00      0.02      0.05        83\n           9       0.82      0.42      0.56       332\n          10       1.00      0.20      0.34        49\n          11       1.00      0.11      0.20       231\n          12       1.00      0.03      0.06       100\n          13       0.00      0.00      0.00        26\n          14       1.00      0.03      0.05        39\n          15       0.00      0.00      0.00        39\n          16       1.00      0.21      0.34       199\n          17       1.00      0.29      0.45        59\n          18       0.86      0.31      0.45        59\n\n   micro avg       0.83      0.20      0.32      1960\n   macro avg       0.71      0.12      0.18      1960\nweighted avg       0.82      0.20      0.28      1960\n samples avg       0.06      0.06      0.06      1960\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"sentences_df = pd.read_csv('/kaggle/input/dl-original/validation/sentences.tsv', sep='\\t')\nlabels_df = pd.read_csv('/kaggle/input/dl-original/validation/labels.tsv', sep='\\t')\ndf1 = sentences_df\ndf2 = labels_df\nimport pandas as pd\nmerged_df = pd.merge(df1, df2, on=['Text-ID', 'Sentence-ID'])\nmerged_df = merged_df[merged_df['Text-ID'].str.contains('EN')]\nmerged_df = merged_df[~merged_df.isin(['0.5', '', pd.NA]).any(axis=1)]\nmerged_df = merged_df.drop(columns=merged_df.columns[:2])\nmerged_df = merged_df[~(merged_df == 0.5).any(axis=1)]\nX = merged_df.iloc[:, :1]  # Assuming the first two columns are features\nY = merged_df.iloc[:, 1:]  # Assuming the rest of the columns are labels\nimport pandas as pd\ncombined_data1 = pd.DataFrame({\n    'Text': X['Text'],\n    'labels': Y.apply(list, axis=1)\n})\nfrom datasets import Dataset\n\ntest_text = combined_data1['Text'].tolist()\ntest_labels = combined_data1['labels'].tolist()\n\n# Create Hugging Face test dataset\ntest_dataset = Dataset.from_dict({'text': test_text, 'labels': test_labels})\n\n# Tokenize the test examples\ntokenized_test_dataset = test_dataset.map(\n    lambda example: tokenizer(example['text']),\n    batched=True,\n)\n\n# Set the format to 'torch'\ntokenized_test_dataset.set_format('torch')\n\n# Test the model\npredictions = trainer.predict(tokenized_test_dataset)\n\n# Convert logits to predicted labels\npredicted_labels = (predictions.predictions > 0).astype(np.int32).tolist()\n\n\n# Add predicted labels to the DataFrame\ncombined_data1['Predicted_Labels'] = predicted_labels\n\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\n# Assuming true_labels and predicted_labels are DataFrame columns\ntrue_labels = combined_data1['labels']\npredicted_labels = combined_data1['Predicted_Labels']\nTL = []\nPL = []\nfor i in true_labels:\n    sub = []\n    for j in i:\n        sub.append(j)\n    TL.append(sub)\nfor i in predicted_labels:\n    sub = []\n    for j in i:\n        sub.append(j)\n    PL.append(sub)\n\n\n\nlabel_namesS = []\nfor i in range(0,38):\n  label_namesS.append(str(i))\nclassification_rep = classification_report(TL,PL, target_names=label_namesS)\nprint(classification_rep)\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\n# Assuming true_labels and predicted_labels are DataFrame columns\ntrue_labels = combined_data1['labels']\npredicted_labels = combined_data1['Predicted_Labels']\nTL = []\nPL = []\nfor i in true_labels:\n    sub = []\n    for j in range(0,len(i),2):\n        a = i[j]\n        b = i[j+1]\n\n        if a + b >= 0.5 :\n\n            sub.append(1)\n\n        else :\n            sub.append(0)\n    TL.append(sub)\n    \nfor i in predicted_labels:\n    sub = []\n    for j in range(0,len(i),2):\n        a = i[j]\n        b = i[j+1]\n\n        if a + b >= 0.5 :\n\n            sub.append(1)\n\n        else :\n            sub.append(0)\n    PL.append(sub)\n\n\n\nlabel_namesS = []\nfor i in range(0,19):\n  label_namesS.append(str(i))\nclassification_rep = classification_report(TL,PL, target_names=label_namesS)\nprint(classification_rep)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-25T15:17:07.212474Z","iopub.execute_input":"2024-03-25T15:17:07.213159Z","iopub.status.idle":"2024-03-25T15:22:16.033227Z","shell.execute_reply.started":"2024-03-25T15:17:07.213125Z","shell.execute_reply":"2024-03-25T15:22:16.032038Z"},"trusted":true},"execution_count":75,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2042 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac2fbe29ac944bc1ab2e7e95581bc2ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         2\n           1       0.00      0.00      0.00         3\n           2       0.00      0.00      0.00        30\n           3       0.00      0.00      0.00        16\n           4       0.00      0.00      0.00        12\n           5       0.00      0.00      0.00         3\n           6       0.00      0.00      0.00        10\n           7       0.00      0.00      0.00         3\n           8       0.47      0.47      0.47        70\n           9       0.00      0.00      0.00        26\n          10       0.00      0.00      0.00        27\n          11       0.00      0.00      0.00        11\n          12       0.00      0.00      0.00        22\n          13       0.00      0.00      0.00        16\n          14       0.00      0.00      0.00         0\n          15       0.00      0.00      0.00        10\n          16       0.00      0.00      0.00        10\n          17       0.00      0.00      0.00        25\n          18       0.58      0.25      0.35        56\n          19       0.52      0.19      0.28        57\n          20       0.00      0.00      0.00        21\n          21       0.00      0.00      0.00         4\n          22       0.50      0.03      0.06        30\n          23       0.00      0.00      0.00        31\n          24       0.00      0.00      0.00         5\n          25       0.00      0.00      0.00        24\n          26       0.00      0.00      0.00         3\n          27       0.00      0.00      0.00         2\n          28       0.00      0.00      0.00        10\n          29       0.00      0.00      0.00         2\n          30       0.00      0.00      0.00        15\n          31       0.00      0.00      0.00         3\n          32       0.67      0.04      0.08        49\n          33       0.00      0.00      0.00        19\n          34       0.00      0.00      0.00        27\n          35       0.00      0.00      0.00        13\n          36       0.00      0.00      0.00         4\n          37       0.00      0.00      0.00         7\n\n   micro avg       0.48      0.09      0.15       678\n   macro avg       0.07      0.03      0.03       678\nweighted avg       0.21      0.09      0.11       678\n samples avg       0.03      0.03      0.03       678\n\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         5\n           1       0.00      0.00      0.00        46\n           2       0.00      0.00      0.00        15\n           3       0.00      0.00      0.00        13\n           4       0.47      0.34      0.40        96\n           5       0.00      0.00      0.00        38\n           6       1.00      0.03      0.05        38\n           7       0.00      0.00      0.00        10\n           8       0.00      0.00      0.00        35\n           9       0.61      0.24      0.34       113\n          10       0.00      0.00      0.00        25\n          11       1.00      0.03      0.06        61\n          12       0.00      0.00      0.00        29\n          13       0.00      0.00      0.00         5\n          14       0.00      0.00      0.00        12\n          15       0.00      0.00      0.00        18\n          16       0.67      0.03      0.06        68\n          17       0.00      0.00      0.00        40\n          18       0.00      0.00      0.00        11\n\n   micro avg       0.52      0.10      0.16       678\n   macro avg       0.20      0.04      0.05       678\nweighted avg       0.38      0.10      0.13       678\n samples avg       0.03      0.03      0.03       678\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}