{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7691911,"sourceType":"datasetVersion","datasetId":4489008}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/dl-dataset/bert_embeddings_data_with_meaningful_names.csv')\ndf.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-24T13:08:18.842843Z","iopub.execute_input":"2024-02-24T13:08:18.843374Z","iopub.status.idle":"2024-02-24T13:08:36.570530Z","shell.execute_reply.started":"2024-02-24T13:08:18.843279Z","shell.execute_reply":"2024-02-24T13:08:36.569387Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"   BERT_Embedding_1  BERT_Embedding_2  BERT_Embedding_3  BERT_Embedding_4  \\\n0          0.497523         -0.874955         -0.024405          0.170007   \n1          0.154767         -0.243211          0.494858          0.726584   \n2         -0.151501         -0.434440         -0.022874          0.248735   \n3         -0.066502         -0.193851          0.090737          0.313518   \n4         -0.008357         -0.596591          0.513910          0.069059   \n\n   BERT_Embedding_5  BERT_Embedding_6  BERT_Embedding_7  BERT_Embedding_8  \\\n0          0.465193         -0.261406          0.120232          0.460818   \n1          0.557604          0.107102         -0.027300          0.320401   \n2          0.248686         -0.151094         -0.864577          0.391631   \n3          0.520956          0.055926         -0.722297          0.369775   \n4          0.285538          0.067322         -0.697802          0.150624   \n\n   BERT_Embedding_9  BERT_Embedding_10  ...  BERT_Embedding_759  \\\n0         -0.427656           0.638674  ...            0.378167   \n1          0.447150           0.512084  ...           -0.003025   \n2          0.156113           0.681767  ...            0.266504   \n3         -0.086349           0.296164  ...            0.159635   \n4          0.004355           0.253117  ...            0.164940   \n\n   BERT_Embedding_760  BERT_Embedding_761  BERT_Embedding_762  \\\n0           -0.180674           -0.538694           -0.934521   \n1            0.064090           -0.531350           -0.522611   \n2            0.135180           -0.086052           -1.006734   \n3            0.401172           -0.410725           -0.651005   \n4            0.562632           -0.269734           -0.967416   \n\n   BERT_Embedding_763  BERT_Embedding_764  BERT_Embedding_765  \\\n0            0.516344            0.416882           -0.618983   \n1            0.494500            0.590308            0.460636   \n2            0.700721           -0.380273           -0.214426   \n3            0.680929           -0.320454            0.045634   \n4            0.849831           -0.098906            0.247863   \n\n   BERT_Embedding_766  BERT_Embedding_767  BERT_Embedding_768  \n0            0.054542            0.026724           -0.427512  \n1            0.274635           -0.125870            0.284757  \n2           -0.111006           -0.155610            0.097264  \n3            0.195799            0.030115            0.107486  \n4            0.158346           -0.128565           -0.169902  \n\n[5 rows x 768 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BERT_Embedding_1</th>\n      <th>BERT_Embedding_2</th>\n      <th>BERT_Embedding_3</th>\n      <th>BERT_Embedding_4</th>\n      <th>BERT_Embedding_5</th>\n      <th>BERT_Embedding_6</th>\n      <th>BERT_Embedding_7</th>\n      <th>BERT_Embedding_8</th>\n      <th>BERT_Embedding_9</th>\n      <th>BERT_Embedding_10</th>\n      <th>...</th>\n      <th>BERT_Embedding_759</th>\n      <th>BERT_Embedding_760</th>\n      <th>BERT_Embedding_761</th>\n      <th>BERT_Embedding_762</th>\n      <th>BERT_Embedding_763</th>\n      <th>BERT_Embedding_764</th>\n      <th>BERT_Embedding_765</th>\n      <th>BERT_Embedding_766</th>\n      <th>BERT_Embedding_767</th>\n      <th>BERT_Embedding_768</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.497523</td>\n      <td>-0.874955</td>\n      <td>-0.024405</td>\n      <td>0.170007</td>\n      <td>0.465193</td>\n      <td>-0.261406</td>\n      <td>0.120232</td>\n      <td>0.460818</td>\n      <td>-0.427656</td>\n      <td>0.638674</td>\n      <td>...</td>\n      <td>0.378167</td>\n      <td>-0.180674</td>\n      <td>-0.538694</td>\n      <td>-0.934521</td>\n      <td>0.516344</td>\n      <td>0.416882</td>\n      <td>-0.618983</td>\n      <td>0.054542</td>\n      <td>0.026724</td>\n      <td>-0.427512</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.154767</td>\n      <td>-0.243211</td>\n      <td>0.494858</td>\n      <td>0.726584</td>\n      <td>0.557604</td>\n      <td>0.107102</td>\n      <td>-0.027300</td>\n      <td>0.320401</td>\n      <td>0.447150</td>\n      <td>0.512084</td>\n      <td>...</td>\n      <td>-0.003025</td>\n      <td>0.064090</td>\n      <td>-0.531350</td>\n      <td>-0.522611</td>\n      <td>0.494500</td>\n      <td>0.590308</td>\n      <td>0.460636</td>\n      <td>0.274635</td>\n      <td>-0.125870</td>\n      <td>0.284757</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.151501</td>\n      <td>-0.434440</td>\n      <td>-0.022874</td>\n      <td>0.248735</td>\n      <td>0.248686</td>\n      <td>-0.151094</td>\n      <td>-0.864577</td>\n      <td>0.391631</td>\n      <td>0.156113</td>\n      <td>0.681767</td>\n      <td>...</td>\n      <td>0.266504</td>\n      <td>0.135180</td>\n      <td>-0.086052</td>\n      <td>-1.006734</td>\n      <td>0.700721</td>\n      <td>-0.380273</td>\n      <td>-0.214426</td>\n      <td>-0.111006</td>\n      <td>-0.155610</td>\n      <td>0.097264</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.066502</td>\n      <td>-0.193851</td>\n      <td>0.090737</td>\n      <td>0.313518</td>\n      <td>0.520956</td>\n      <td>0.055926</td>\n      <td>-0.722297</td>\n      <td>0.369775</td>\n      <td>-0.086349</td>\n      <td>0.296164</td>\n      <td>...</td>\n      <td>0.159635</td>\n      <td>0.401172</td>\n      <td>-0.410725</td>\n      <td>-0.651005</td>\n      <td>0.680929</td>\n      <td>-0.320454</td>\n      <td>0.045634</td>\n      <td>0.195799</td>\n      <td>0.030115</td>\n      <td>0.107486</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.008357</td>\n      <td>-0.596591</td>\n      <td>0.513910</td>\n      <td>0.069059</td>\n      <td>0.285538</td>\n      <td>0.067322</td>\n      <td>-0.697802</td>\n      <td>0.150624</td>\n      <td>0.004355</td>\n      <td>0.253117</td>\n      <td>...</td>\n      <td>0.164940</td>\n      <td>0.562632</td>\n      <td>-0.269734</td>\n      <td>-0.967416</td>\n      <td>0.849831</td>\n      <td>-0.098906</td>\n      <td>0.247863</td>\n      <td>0.158346</td>\n      <td>-0.128565</td>\n      <td>-0.169902</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 768 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:08:36.572783Z","iopub.execute_input":"2024-02-24T13:08:36.573156Z","iopub.status.idle":"2024-02-24T13:08:36.579135Z","shell.execute_reply.started":"2024-02-24T13:08:36.573125Z","shell.execute_reply":"2024-02-24T13:08:36.578029Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(40665, 768)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf1 = pd.read_csv('/kaggle/input/dl-dataset/sentencesTR.tsv', sep='\\t')\nprint(df1.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:08:42.536045Z","iopub.execute_input":"2024-02-24T13:08:42.536477Z","iopub.status.idle":"2024-02-24T13:08:42.781582Z","shell.execute_reply.started":"2024-02-24T13:08:42.536443Z","shell.execute_reply":"2024-02-24T13:08:42.780266Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(40667, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf2 = pd.read_csv('/kaggle/input/dl-dataset/labelsTR.tsv', sep='\\t')\nprint(df2.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:08:58.481156Z","iopub.execute_input":"2024-02-24T13:08:58.481575Z","iopub.status.idle":"2024-02-24T13:08:58.755547Z","shell.execute_reply.started":"2024-02-24T13:08:58.481544Z","shell.execute_reply":"2024-02-24T13:08:58.754152Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(40667, 40)\n","output_type":"stream"}]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:09:04.458139Z","iopub.execute_input":"2024-02-24T13:09:04.458582Z","iopub.status.idle":"2024-02-24T13:09:04.527436Z","shell.execute_reply.started":"2024-02-24T13:09:04.458550Z","shell.execute_reply":"2024-02-24T13:09:04.526105Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        Text-ID  Sentence-ID  Self-direction: thought attained  \\\n0        BG_002            1                               0.0   \n1        BG_002            2                               0.0   \n2        BG_002            3                               0.0   \n3        BG_002            4                               0.0   \n4        BG_002            5                               0.0   \n...         ...          ...                               ...   \n40662  TR_M_022           12                               0.0   \n40663  TR_M_022           13                               0.0   \n40664  TR_M_022           14                               0.0   \n40665  TR_M_022           15                               0.0   \n40666  TR_M_022           16                               0.0   \n\n       Self-direction: thought constrained  Self-direction: action attained  \\\n0                                      0.0                              0.0   \n1                                      0.0                              0.0   \n2                                      0.0                              0.0   \n3                                      0.0                              0.0   \n4                                      0.0                              0.0   \n...                                    ...                              ...   \n40662                                  0.0                              0.0   \n40663                                  0.0                              0.0   \n40664                                  0.0                              0.0   \n40665                                  0.0                              1.0   \n40666                                  0.0                              0.0   \n\n       Self-direction: action constrained  Stimulation attained  \\\n0                                     0.0                   0.0   \n1                                     0.0                   0.0   \n2                                     0.0                   0.0   \n3                                     0.0                   0.0   \n4                                     0.0                   0.0   \n...                                   ...                   ...   \n40662                                 0.0                   0.5   \n40663                                 0.0                   0.0   \n40664                                 0.0                   0.0   \n40665                                 0.0                   0.0   \n40666                                 0.0                   0.0   \n\n       Stimulation constrained  Hedonism attained  Hedonism constrained  ...  \\\n0                          0.0                0.0                   0.0  ...   \n1                          0.0                0.0                   0.0  ...   \n2                          0.0                1.0                   0.0  ...   \n3                          0.0                0.0                   0.0  ...   \n4                          0.0                0.0                   0.0  ...   \n...                        ...                ...                   ...  ...   \n40662                      0.5                0.0                   0.0  ...   \n40663                      0.0                0.0                   0.0  ...   \n40664                      0.0                0.0                   0.0  ...   \n40665                      0.0                0.0                   0.0  ...   \n40666                      0.0                0.0                   0.0  ...   \n\n       Benevolence: caring attained  Benevolence: caring constrained  \\\n0                               0.0                              0.0   \n1                               0.0                              0.0   \n2                               0.0                              0.0   \n3                               0.0                              0.0   \n4                               0.0                              0.0   \n...                             ...                              ...   \n40662                           0.0                              0.0   \n40663                           1.0                              0.0   \n40664                           0.0                              0.0   \n40665                           1.0                              0.0   \n40666                           1.0                              0.0   \n\n       Benevolence: dependability attained  \\\n0                                      0.0   \n1                                      0.0   \n2                                      0.0   \n3                                      0.0   \n4                                      0.0   \n...                                    ...   \n40662                                  0.0   \n40663                                  0.0   \n40664                                  0.0   \n40665                                  0.0   \n40666                                  0.0   \n\n       Benevolence: dependability constrained  Universalism: concern attained  \\\n0                                         0.0                             0.0   \n1                                         0.0                             0.0   \n2                                         0.0                             0.0   \n3                                         0.0                             0.0   \n4                                         0.0                             0.0   \n...                                       ...                             ...   \n40662                                     0.0                             0.0   \n40663                                     0.0                             0.0   \n40664                                     0.0                             0.0   \n40665                                     0.0                             0.0   \n40666                                     0.0                             0.0   \n\n       Universalism: concern constrained  Universalism: nature attained  \\\n0                                    0.0                            0.0   \n1                                    0.0                            0.0   \n2                                    0.0                            0.0   \n3                                    0.0                            0.0   \n4                                    0.0                            0.0   \n...                                  ...                            ...   \n40662                                0.0                            0.0   \n40663                                0.0                            0.0   \n40664                                0.0                            0.0   \n40665                                0.0                            0.0   \n40666                                0.0                            0.0   \n\n       Universalism: nature constrained  Universalism: tolerance attained  \\\n0                                   0.0                               0.0   \n1                                   0.0                               0.0   \n2                                   0.0                               0.0   \n3                                   0.0                               0.0   \n4                                   0.0                               0.0   \n...                                 ...                               ...   \n40662                               0.0                               0.0   \n40663                               0.0                               0.0   \n40664                               0.0                               0.0   \n40665                               0.0                               0.0   \n40666                               0.0                               0.0   \n\n       Universalism: tolerance constrained  \n0                                      0.0  \n1                                      0.0  \n2                                      0.0  \n3                                      0.0  \n4                                      0.0  \n...                                    ...  \n40662                                  0.0  \n40663                                  0.0  \n40664                                  0.0  \n40665                                  0.0  \n40666                                  0.0  \n\n[40667 rows x 40 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text-ID</th>\n      <th>Sentence-ID</th>\n      <th>Self-direction: thought attained</th>\n      <th>Self-direction: thought constrained</th>\n      <th>Self-direction: action attained</th>\n      <th>Self-direction: action constrained</th>\n      <th>Stimulation attained</th>\n      <th>Stimulation constrained</th>\n      <th>Hedonism attained</th>\n      <th>Hedonism constrained</th>\n      <th>...</th>\n      <th>Benevolence: caring attained</th>\n      <th>Benevolence: caring constrained</th>\n      <th>Benevolence: dependability attained</th>\n      <th>Benevolence: dependability constrained</th>\n      <th>Universalism: concern attained</th>\n      <th>Universalism: concern constrained</th>\n      <th>Universalism: nature attained</th>\n      <th>Universalism: nature constrained</th>\n      <th>Universalism: tolerance attained</th>\n      <th>Universalism: tolerance constrained</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BG_002</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BG_002</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BG_002</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BG_002</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BG_002</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>40662</th>\n      <td>TR_M_022</td>\n      <td>12</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40663</th>\n      <td>TR_M_022</td>\n      <td>13</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40664</th>\n      <td>TR_M_022</td>\n      <td>14</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40665</th>\n      <td>TR_M_022</td>\n      <td>15</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40666</th>\n      <td>TR_M_022</td>\n      <td>16</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>40667 rows Ã— 40 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nindexes_null_rows = df1[df1.isnull().any(axis=1)].index\nprint(indexes_null_rows)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:09:12.626832Z","iopub.execute_input":"2024-02-24T13:09:12.627269Z","iopub.status.idle":"2024-02-24T13:09:12.647279Z","shell.execute_reply.started":"2024-02-24T13:09:12.627231Z","shell.execute_reply":"2024-02-24T13:09:12.646164Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Index([33726, 33787], dtype='int64')\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf1.drop(indexes_null_rows, inplace=True)\nprint(df1.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:09:18.762709Z","iopub.execute_input":"2024-02-24T13:09:18.763106Z","iopub.status.idle":"2024-02-24T13:09:18.778262Z","shell.execute_reply.started":"2024-02-24T13:09:18.763075Z","shell.execute_reply":"2024-02-24T13:09:18.776838Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(40665, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf2.drop(indexes_null_rows, inplace=True)\nprint(df2.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:09:43.684272Z","iopub.execute_input":"2024-02-24T13:09:43.684719Z","iopub.status.idle":"2024-02-24T13:09:43.707631Z","shell.execute_reply.started":"2024-02-24T13:09:43.684688Z","shell.execute_reply":"2024-02-24T13:09:43.706546Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(40665, 40)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfeatures_2d_list = df.values.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:09:45.864778Z","iopub.execute_input":"2024-02-24T13:09:45.865234Z","iopub.status.idle":"2024-02-24T13:09:50.708542Z","shell.execute_reply.started":"2024-02-24T13:09:45.865201Z","shell.execute_reply":"2024-02-24T13:09:50.707391Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df2 = df2.iloc[:, 2:]","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:09:54.007925Z","iopub.execute_input":"2024-02-24T13:09:54.008401Z","iopub.status.idle":"2024-02-24T13:09:54.017758Z","shell.execute_reply.started":"2024-02-24T13:09:54.008367Z","shell.execute_reply":"2024-02-24T13:09:54.016264Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfeatures_2d_list2 = df2.values.tolist()\nprint(len(features_2d_list2[0]))","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:09:59.371719Z","iopub.execute_input":"2024-02-24T13:09:59.372108Z","iopub.status.idle":"2024-02-24T13:09:59.523756Z","shell.execute_reply.started":"2024-02-24T13:09:59.372069Z","shell.execute_reply":"2024-02-24T13:09:59.521048Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"38\n","output_type":"stream"}]},{"cell_type":"code","source":"X = features_2d_list\nY = features_2d_list2","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:10:04.416933Z","iopub.execute_input":"2024-02-24T13:10:04.417399Z","iopub.status.idle":"2024-02-24T13:10:04.423600Z","shell.execute_reply.started":"2024-02-24T13:10:04.417364Z","shell.execute_reply":"2024-02-24T13:10:04.422106Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"ans = []","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:10:09.930591Z","iopub.execute_input":"2024-02-24T13:10:09.931019Z","iopub.status.idle":"2024-02-24T13:10:09.937013Z","shell.execute_reply.started":"2024-02-24T13:10:09.930988Z","shell.execute_reply":"2024-02-24T13:10:09.935515Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for i in Y :\n    sub = []\n    for j in i :\n        if j == 1.0 : \n            sub.extend([1,0,0])\n        elif j == 0.5 : \n            sub.extend([0,1,0])\n        else : \n            sub.extend([0,0,1])\n    ans.append(sub)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:10:16.063986Z","iopub.execute_input":"2024-02-24T13:10:16.064448Z","iopub.status.idle":"2024-02-24T13:10:16.687875Z","shell.execute_reply.started":"2024-02-24T13:10:16.064415Z","shell.execute_reply":"2024-02-24T13:10:16.686583Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"Y = ans","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:10:29.425346Z","iopub.execute_input":"2024-02-24T13:10:29.425733Z","iopub.status.idle":"2024-02-24T13:10:29.431788Z","shell.execute_reply.started":"2024-02-24T13:10:29.425705Z","shell.execute_reply":"2024-02-24T13:10:29.430351Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n\nknn = KNeighborsClassifier()\nmulti_target_knn = MultiOutputClassifier(knn)\nprint(\"Training started...\")\nmulti_target_knn.fit(X_train, Y_train)\nprint(\"Training completed.\")\n\npredictions = multi_target_knn.predict(X_test)\n\naccuracy = accuracy_score(Y_test, predictions)\n\nprint(\"Accuracy:\", accuracy)\n\nreport = classification_report(Y_test, predictions)\nprint(\"Classification Report:\\n\", report)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:13:39.145301Z","iopub.execute_input":"2024-02-24T13:13:39.145769Z","iopub.status.idle":"2024-02-24T13:34:16.965661Z","shell.execute_reply.started":"2024-02-24T13:13:39.145738Z","shell.execute_reply":"2024-02-24T13:34:16.964508Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Training started...\nTraining completed.\nAccuracy: 0.5027665068240502\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        70\n           1       0.00      0.00      0.00         9\n           2       0.99      1.00      1.00      8054\n           3       0.00      0.00      0.00        13\n           4       0.00      0.00      0.00         9\n           5       1.00      1.00      1.00      8111\n           6       0.29      0.02      0.04       217\n           7       0.00      0.00      0.00        16\n           8       0.97      1.00      0.98      7900\n           9       1.00      0.02      0.04        51\n          10       0.00      0.00      0.00        16\n          11       0.99      1.00      1.00      8066\n          12       0.22      0.01      0.02       157\n          13       0.00      0.00      0.00        18\n          14       0.98      1.00      0.99      7958\n          15       0.00      0.00      0.00        25\n          16       0.00      0.00      0.00        18\n          17       0.99      1.00      1.00      8090\n          18       1.00      0.02      0.03        57\n          19       0.00      0.00      0.00         4\n          20       0.99      1.00      1.00      8072\n          21       0.00      0.00      0.00        28\n          22       0.00      0.00      0.00         4\n          23       1.00      1.00      1.00      8101\n          24       0.35      0.05      0.09       357\n          25       0.00      0.00      0.00        30\n          26       0.95      0.99      0.97      7746\n          27       0.53      0.05      0.10       149\n          28       0.00      0.00      0.00        30\n          29       0.98      1.00      0.99      7954\n          30       0.43      0.05      0.09       246\n          31       0.00      0.00      0.00        41\n          32       0.97      1.00      0.98      7846\n          33       0.00      0.00      0.00        55\n          34       0.00      0.00      0.00        41\n          35       0.99      1.00      0.99      8037\n          36       0.44      0.08      0.13       230\n          37       0.00      0.00      0.00        42\n          38       0.97      1.00      0.98      7861\n          39       0.33      0.02      0.04       154\n          40       0.00      0.00      0.00        42\n          41       0.98      1.00      0.99      7937\n          42       0.00      0.00      0.00        66\n          43       0.00      0.00      0.00        11\n          44       0.99      1.00      1.00      8056\n          45       0.00      0.00      0.00        62\n          46       0.00      0.00      0.00        11\n          47       0.99      1.00      1.00      8060\n          48       0.40      0.04      0.07        50\n          49       0.00      0.00      0.00        11\n          50       0.99      1.00      1.00      8072\n          51       0.20      0.01      0.02       106\n          52       0.00      0.00      0.00        11\n          53       0.99      1.00      0.99      8016\n          54       0.26      0.04      0.07       264\n          55       0.00      0.00      0.00        31\n          56       0.97      1.00      0.98      7838\n          57       0.33      0.05      0.09       395\n          58       0.00      0.00      0.00        31\n          59       0.95      0.99      0.97      7707\n          60       0.50      0.05      0.09        62\n          61       0.00      0.00      0.00         7\n          62       0.99      1.00      1.00      8064\n          63       0.00      0.00      0.00        20\n          64       0.00      0.00      0.00         7\n          65       1.00      1.00      1.00      8106\n          66       0.39      0.07      0.12       244\n          67       0.50      0.04      0.07        57\n          68       0.97      1.00      0.98      7832\n          69       0.27      0.02      0.04       172\n          70       0.50      0.04      0.07        57\n          71       0.97      1.00      0.98      7904\n          72       0.00      0.00      0.00        44\n          73       0.00      0.00      0.00         5\n          74       0.99      1.00      1.00      8084\n          75       0.25      0.02      0.03        61\n          76       0.00      0.00      0.00         5\n          77       0.99      1.00      1.00      8067\n          78       0.00      0.00      0.00         6\n          79       0.00      0.00      0.00         0\n          80       1.00      1.00      1.00      8127\n          81       0.00      0.00      0.00         5\n          82       0.00      0.00      0.00         0\n          83       1.00      1.00      1.00      8128\n          84       0.31      0.03      0.06       149\n          85       0.00      0.00      0.00        12\n          86       0.98      1.00      0.99      7972\n          87       0.00      0.00      0.00        25\n          88       0.00      0.00      0.00        12\n          89       1.00      1.00      1.00      8096\n          90       0.20      0.01      0.02       107\n          91       0.00      0.00      0.00        10\n          92       0.99      1.00      0.99      8016\n          93       0.00      0.00      0.00        35\n          94       0.00      0.00      0.00        10\n          95       0.99      1.00      1.00      8088\n          96       0.38      0.05      0.08       220\n          97       0.00      0.00      0.00        19\n          98       0.97      1.00      0.98      7894\n          99       0.29      0.01      0.03       143\n         100       0.00      0.00      0.00        19\n         101       0.98      1.00      0.99      7971\n         102       0.57      0.08      0.14       104\n         103       0.00      0.00      0.00         6\n         104       0.99      1.00      0.99      8023\n         105       0.00      0.00      0.00        49\n         106       0.00      0.00      0.00         6\n         107       0.99      1.00      1.00      8078\n         108       0.00      0.00      0.00        33\n         109       0.00      0.00      0.00         2\n         110       1.00      1.00      1.00      8098\n         111       1.00      0.04      0.09        45\n         112       0.00      0.00      0.00         2\n         113       0.99      1.00      1.00      8086\n\n   micro avg       0.98      0.98      0.98    309054\n   macro avg       0.42      0.34      0.35    309054\nweighted avg       0.97      0.98      0.98    309054\n samples avg       0.98      0.98      0.98    309054\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndfVAL = pd.read_csv('/kaggle/input/dl-dataset/bert_embeddings_dataVAL.csv')\ndfVAL.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:35:15.929891Z","iopub.execute_input":"2024-02-24T13:35:15.930355Z","iopub.status.idle":"2024-02-24T13:35:20.894302Z","shell.execute_reply.started":"2024-02-24T13:35:15.930306Z","shell.execute_reply":"2024-02-24T13:35:20.893125Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"   BERT_Embedding_1  BERT_Embedding_2  BERT_Embedding_3  BERT_Embedding_4  \\\n0          0.045752          0.207497          1.099266          0.452144   \n1         -0.217727         -0.634583         -0.205927          0.259115   \n2         -0.166217         -0.671090         -0.226426          0.359209   \n3         -0.070785         -0.290688         -0.459893          0.254353   \n4         -0.266292         -0.303938          0.251785          0.419387   \n\n   BERT_Embedding_5  BERT_Embedding_6  BERT_Embedding_7  BERT_Embedding_8  \\\n0          0.554111          0.073297         -0.014080         -0.078388   \n1         -0.211272          0.104173         -0.240467         -0.181109   \n2          0.148180          0.234899         -0.461270          0.143547   \n3          0.320646          0.296400         -0.052740          0.160761   \n4          0.398838         -0.020577         -0.169708          0.388015   \n\n   BERT_Embedding_9  BERT_Embedding_10  ...  BERT_Embedding_759  \\\n0         -0.413492           0.187055  ...           -0.102681   \n1         -0.211698           0.090513  ...            0.167463   \n2         -0.036923           0.160838  ...            0.185205   \n3          0.025161           0.172166  ...           -0.082233   \n4         -0.276377          -0.065725  ...            0.021161   \n\n   BERT_Embedding_760  BERT_Embedding_761  BERT_Embedding_762  \\\n0           -0.172996           -0.378343           -0.304220   \n1            0.254222           -0.482718           -1.185368   \n2            0.293960           -0.464208           -1.174751   \n3            0.276296           -0.188936           -0.735082   \n4            0.442678           -0.184714           -0.942429   \n\n   BERT_Embedding_763  BERT_Embedding_764  BERT_Embedding_765  \\\n0            0.194587           -0.049413            0.492155   \n1            0.567221           -0.308310           -0.310004   \n2            0.377679           -0.368274           -0.194255   \n3            0.388586           -0.058073            0.175509   \n4            0.404701           -0.231231           -0.059942   \n\n   BERT_Embedding_766  BERT_Embedding_767  BERT_Embedding_768  \n0           -0.077701            0.517066           -0.075426  \n1            0.454447            0.461759           -0.002930  \n2            0.444923            0.337722            0.103220  \n3            0.081045            0.376520            0.148483  \n4            0.045978            0.277905            0.079513  \n\n[5 rows x 768 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BERT_Embedding_1</th>\n      <th>BERT_Embedding_2</th>\n      <th>BERT_Embedding_3</th>\n      <th>BERT_Embedding_4</th>\n      <th>BERT_Embedding_5</th>\n      <th>BERT_Embedding_6</th>\n      <th>BERT_Embedding_7</th>\n      <th>BERT_Embedding_8</th>\n      <th>BERT_Embedding_9</th>\n      <th>BERT_Embedding_10</th>\n      <th>...</th>\n      <th>BERT_Embedding_759</th>\n      <th>BERT_Embedding_760</th>\n      <th>BERT_Embedding_761</th>\n      <th>BERT_Embedding_762</th>\n      <th>BERT_Embedding_763</th>\n      <th>BERT_Embedding_764</th>\n      <th>BERT_Embedding_765</th>\n      <th>BERT_Embedding_766</th>\n      <th>BERT_Embedding_767</th>\n      <th>BERT_Embedding_768</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.045752</td>\n      <td>0.207497</td>\n      <td>1.099266</td>\n      <td>0.452144</td>\n      <td>0.554111</td>\n      <td>0.073297</td>\n      <td>-0.014080</td>\n      <td>-0.078388</td>\n      <td>-0.413492</td>\n      <td>0.187055</td>\n      <td>...</td>\n      <td>-0.102681</td>\n      <td>-0.172996</td>\n      <td>-0.378343</td>\n      <td>-0.304220</td>\n      <td>0.194587</td>\n      <td>-0.049413</td>\n      <td>0.492155</td>\n      <td>-0.077701</td>\n      <td>0.517066</td>\n      <td>-0.075426</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.217727</td>\n      <td>-0.634583</td>\n      <td>-0.205927</td>\n      <td>0.259115</td>\n      <td>-0.211272</td>\n      <td>0.104173</td>\n      <td>-0.240467</td>\n      <td>-0.181109</td>\n      <td>-0.211698</td>\n      <td>0.090513</td>\n      <td>...</td>\n      <td>0.167463</td>\n      <td>0.254222</td>\n      <td>-0.482718</td>\n      <td>-1.185368</td>\n      <td>0.567221</td>\n      <td>-0.308310</td>\n      <td>-0.310004</td>\n      <td>0.454447</td>\n      <td>0.461759</td>\n      <td>-0.002930</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.166217</td>\n      <td>-0.671090</td>\n      <td>-0.226426</td>\n      <td>0.359209</td>\n      <td>0.148180</td>\n      <td>0.234899</td>\n      <td>-0.461270</td>\n      <td>0.143547</td>\n      <td>-0.036923</td>\n      <td>0.160838</td>\n      <td>...</td>\n      <td>0.185205</td>\n      <td>0.293960</td>\n      <td>-0.464208</td>\n      <td>-1.174751</td>\n      <td>0.377679</td>\n      <td>-0.368274</td>\n      <td>-0.194255</td>\n      <td>0.444923</td>\n      <td>0.337722</td>\n      <td>0.103220</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.070785</td>\n      <td>-0.290688</td>\n      <td>-0.459893</td>\n      <td>0.254353</td>\n      <td>0.320646</td>\n      <td>0.296400</td>\n      <td>-0.052740</td>\n      <td>0.160761</td>\n      <td>0.025161</td>\n      <td>0.172166</td>\n      <td>...</td>\n      <td>-0.082233</td>\n      <td>0.276296</td>\n      <td>-0.188936</td>\n      <td>-0.735082</td>\n      <td>0.388586</td>\n      <td>-0.058073</td>\n      <td>0.175509</td>\n      <td>0.081045</td>\n      <td>0.376520</td>\n      <td>0.148483</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.266292</td>\n      <td>-0.303938</td>\n      <td>0.251785</td>\n      <td>0.419387</td>\n      <td>0.398838</td>\n      <td>-0.020577</td>\n      <td>-0.169708</td>\n      <td>0.388015</td>\n      <td>-0.276377</td>\n      <td>-0.065725</td>\n      <td>...</td>\n      <td>0.021161</td>\n      <td>0.442678</td>\n      <td>-0.184714</td>\n      <td>-0.942429</td>\n      <td>0.404701</td>\n      <td>-0.231231</td>\n      <td>-0.059942</td>\n      <td>0.045978</td>\n      <td>0.277905</td>\n      <td>0.079513</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 768 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ndfVALL = pd.read_csv('/kaggle/input/dl-dataset/labels.tsv',sep='\\t')\ndfVALL.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:35:56.076815Z","iopub.execute_input":"2024-02-24T13:35:56.077232Z","iopub.status.idle":"2024-02-24T13:35:56.204056Z","shell.execute_reply.started":"2024-02-24T13:35:56.077202Z","shell.execute_reply":"2024-02-24T13:35:56.202612Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"  Text-ID  Sentence-ID  Self-direction: thought attained  \\\n0  BG_005            1                               0.0   \n1  BG_005            2                               0.0   \n2  BG_005            3                               0.0   \n3  BG_005            4                               0.0   \n4  BG_005            5                               0.0   \n\n   Self-direction: thought constrained  Self-direction: action attained  \\\n0                                  0.0                              0.0   \n1                                  0.0                              0.0   \n2                                  0.0                              0.0   \n3                                  0.0                              0.0   \n4                                  0.0                              0.0   \n\n   Self-direction: action constrained  Stimulation attained  \\\n0                                 0.0                   0.0   \n1                                 0.0                   0.0   \n2                                 0.0                   0.0   \n3                                 0.0                   0.0   \n4                                 0.0                   0.0   \n\n   Stimulation constrained  Hedonism attained  Hedonism constrained  ...  \\\n0                      0.0                0.0                   0.0  ...   \n1                      0.0                0.0                   0.0  ...   \n2                      0.0                0.0                   0.0  ...   \n3                      0.0                0.0                   0.0  ...   \n4                      0.0                0.0                   0.0  ...   \n\n   Benevolence: caring attained  Benevolence: caring constrained  \\\n0                           0.0                              0.0   \n1                           0.0                              0.0   \n2                           0.0                              0.0   \n3                           0.0                              0.0   \n4                           0.0                              0.0   \n\n   Benevolence: dependability attained  \\\n0                                  0.0   \n1                                  0.0   \n2                                  0.0   \n3                                  0.0   \n4                                  0.0   \n\n   Benevolence: dependability constrained  Universalism: concern attained  \\\n0                                     0.0                             0.0   \n1                                     0.0                             0.0   \n2                                     0.0                             0.0   \n3                                     0.0                             0.0   \n4                                     0.0                             0.0   \n\n   Universalism: concern constrained  Universalism: nature attained  \\\n0                                0.0                            0.0   \n1                                0.0                            0.0   \n2                                0.0                            0.0   \n3                                0.0                            0.0   \n4                                0.0                            0.0   \n\n   Universalism: nature constrained  Universalism: tolerance attained  \\\n0                               0.0                               0.0   \n1                               0.0                               0.0   \n2                               1.0                               0.0   \n3                               0.0                               0.0   \n4                               0.0                               0.0   \n\n   Universalism: tolerance constrained  \n0                                  0.0  \n1                                  0.0  \n2                                  0.0  \n3                                  0.0  \n4                                  0.0  \n\n[5 rows x 40 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text-ID</th>\n      <th>Sentence-ID</th>\n      <th>Self-direction: thought attained</th>\n      <th>Self-direction: thought constrained</th>\n      <th>Self-direction: action attained</th>\n      <th>Self-direction: action constrained</th>\n      <th>Stimulation attained</th>\n      <th>Stimulation constrained</th>\n      <th>Hedonism attained</th>\n      <th>Hedonism constrained</th>\n      <th>...</th>\n      <th>Benevolence: caring attained</th>\n      <th>Benevolence: caring constrained</th>\n      <th>Benevolence: dependability attained</th>\n      <th>Benevolence: dependability constrained</th>\n      <th>Universalism: concern attained</th>\n      <th>Universalism: concern constrained</th>\n      <th>Universalism: nature attained</th>\n      <th>Universalism: nature constrained</th>\n      <th>Universalism: tolerance attained</th>\n      <th>Universalism: tolerance constrained</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BG_005</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BG_005</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BG_005</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BG_005</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BG_005</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 40 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Shape of the DataFrame:\",dfVAL.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:44:00.737935Z","iopub.execute_input":"2024-02-24T13:44:00.739417Z","iopub.status.idle":"2024-02-24T13:44:00.745488Z","shell.execute_reply.started":"2024-02-24T13:44:00.739369Z","shell.execute_reply":"2024-02-24T13:44:00.744244Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Shape of the DataFrame: (13584, 768)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Shape of the DataFrame:\",dfVALL.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:44:06.714149Z","iopub.execute_input":"2024-02-24T13:44:06.715071Z","iopub.status.idle":"2024-02-24T13:44:06.721831Z","shell.execute_reply.started":"2024-02-24T13:44:06.715019Z","shell.execute_reply":"2024-02-24T13:44:06.720059Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Shape of the DataFrame: (13585, 40)\n","output_type":"stream"}]},{"cell_type":"code","source":"dfVALL = dfVALL.drop(11078)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:46:24.436548Z","iopub.execute_input":"2024-02-24T13:46:24.436968Z","iopub.status.idle":"2024-02-24T13:46:24.446439Z","shell.execute_reply.started":"2024-02-24T13:46:24.436938Z","shell.execute_reply":"2024-02-24T13:46:24.445312Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"dfVALL = dfVALL.iloc[:, 2:]","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:47:29.241809Z","iopub.execute_input":"2024-02-24T13:47:29.242326Z","iopub.status.idle":"2024-02-24T13:47:29.250536Z","shell.execute_reply.started":"2024-02-24T13:47:29.242277Z","shell.execute_reply":"2024-02-24T13:47:29.248808Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfeatures_2d_list2 = dfVALL.values.tolist()\nY = features_2d_list2","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:48:42.981701Z","iopub.execute_input":"2024-02-24T13:48:42.982143Z","iopub.status.idle":"2024-02-24T13:48:43.036667Z","shell.execute_reply.started":"2024-02-24T13:48:42.982110Z","shell.execute_reply":"2024-02-24T13:48:43.034729Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"ans = []\nfor i in Y :\n    sub = []\n    for j in i :\n        if j == 1.0 : \n            sub.extend([1,0,0])\n        elif j == 0.5 : \n            sub.extend([0,1,0])\n        else : \n            sub.extend([0,0,1])\n    ans.append(sub)\nY=ans","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:48:44.030664Z","iopub.execute_input":"2024-02-24T13:48:44.031207Z","iopub.status.idle":"2024-02-24T13:48:44.255098Z","shell.execute_reply.started":"2024-02-24T13:48:44.031169Z","shell.execute_reply":"2024-02-24T13:48:44.253783Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"features_2d_list = dfVAL.values.tolist()\nX = features_2d_list ","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:49:40.683348Z","iopub.execute_input":"2024-02-24T13:49:40.683783Z","iopub.status.idle":"2024-02-24T13:49:41.611127Z","shell.execute_reply.started":"2024-02-24T13:49:40.683750Z","shell.execute_reply":"2024-02-24T13:49:41.609979Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"predictions = multi_target_knn.predict(X)\n\naccuracy = accuracy_score(Y, predictions)\n\nprint(\"Accuracy:\", accuracy)\n\nreport = classification_report(Y, predictions)\nprint(\"Classification Report:\\n\", report)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T13:50:51.193751Z","iopub.execute_input":"2024-02-24T13:50:51.194213Z","iopub.status.idle":"2024-02-24T14:17:20.851521Z","shell.execute_reply.started":"2024-02-24T13:50:51.194182Z","shell.execute_reply":"2024-02-24T14:17:20.849924Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Accuracy: 0.49403710247349825\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00       118\n           1       0.00      0.00      0.00         7\n           2       0.99      1.00      1.00     13459\n           3       0.00      0.00      0.00        27\n           4       0.00      0.00      0.00         7\n           5       1.00      1.00      1.00     13550\n           6       0.15      0.01      0.02       308\n           7       0.00      0.00      0.00        12\n           8       0.98      1.00      0.99     13264\n           9       0.00      0.00      0.00        88\n          10       0.00      0.00      0.00        12\n          11       0.99      1.00      1.00     13484\n          12       0.10      0.01      0.01       305\n          13       0.00      0.00      0.00        18\n          14       0.98      1.00      0.99     13261\n          15       0.00      0.00      0.00        34\n          16       0.00      0.00      0.00        18\n          17       1.00      1.00      1.00     13532\n          18       0.00      0.00      0.00        71\n          19       0.00      0.00      0.00         1\n          20       0.99      1.00      1.00     13512\n          21       0.00      0.00      0.00        27\n          22       0.00      0.00      0.00         1\n          23       1.00      1.00      1.00     13556\n          24       0.18      0.01      0.02       623\n          25       0.00      0.00      0.00        43\n          26       0.95      1.00      0.97     12918\n          27       0.26      0.02      0.05       202\n          28       0.00      0.00      0.00        43\n          29       0.98      1.00      0.99     13339\n          30       0.17      0.02      0.04       368\n          31       0.25      0.02      0.03        61\n          32       0.97      0.99      0.98     13155\n          33       1.00      0.01      0.02       109\n          34       0.25      0.02      0.03        61\n          35       0.99      1.00      0.99     13414\n          36       0.23      0.04      0.06       412\n          37       0.00      0.00      0.00        67\n          38       0.97      0.99      0.98     13105\n          39       0.21      0.02      0.03       179\n          40       0.00      0.00      0.00        67\n          41       0.98      1.00      0.99     13338\n          42       0.00      0.00      0.00       102\n          43       0.00      0.00      0.00        19\n          44       0.99      1.00      1.00     13463\n          45       0.00      0.00      0.00       131\n          46       0.00      0.00      0.00        19\n          47       0.99      1.00      0.99     13434\n          48       0.00      0.00      0.00        65\n          49       0.00      0.00      0.00        11\n          50       0.99      1.00      1.00     13508\n          51       0.00      0.00      0.00       173\n          52       0.00      0.00      0.00        11\n          53       0.99      1.00      0.99     13400\n          54       0.12      0.01      0.02       432\n          55       0.00      0.00      0.00        43\n          56       0.97      1.00      0.98     13109\n          57       0.29      0.05      0.08       630\n          58       0.00      0.00      0.00        43\n          59       0.95      0.99      0.97     12911\n          60       1.00      0.01      0.01       176\n          61       0.00      0.00      0.00        14\n          62       0.99      1.00      0.99     13394\n          63       0.00      0.00      0.00        32\n          64       0.00      0.00      0.00        14\n          65       1.00      1.00      1.00     13538\n          66       0.16      0.02      0.03       460\n          67       0.50      0.01      0.02        82\n          68       0.96      0.99      0.98     13042\n          69       0.15      0.01      0.02       294\n          70       0.50      0.01      0.02        82\n          71       0.97      1.00      0.98     13208\n          72       0.00      0.00      0.00        66\n          73       0.00      0.00      0.00         8\n          74       0.99      1.00      1.00     13510\n          75       0.33      0.01      0.02       107\n          76       0.00      0.00      0.00         8\n          77       0.99      1.00      1.00     13469\n          78       0.00      0.00      0.00        30\n          79       0.00      0.00      0.00         0\n          80       1.00      1.00      1.00     13554\n          81       0.00      0.00      0.00         7\n          82       0.00      0.00      0.00         0\n          83       1.00      1.00      1.00     13577\n          84       0.14      0.01      0.03       277\n          85       0.00      0.00      0.00        12\n          86       0.98      1.00      0.99     13295\n          87       0.00      0.00      0.00        37\n          88       0.00      0.00      0.00        12\n          89       1.00      1.00      1.00     13535\n          90       0.00      0.00      0.00       217\n          91       0.00      0.00      0.00         5\n          92       0.98      1.00      0.99     13362\n          93       0.00      0.00      0.00        38\n          94       0.00      0.00      0.00         5\n          95       1.00      1.00      1.00     13541\n          96       0.10      0.01      0.01       374\n          97       0.00      0.00      0.00        25\n          98       0.97      1.00      0.98     13185\n          99       0.00      0.00      0.00       170\n         100       0.00      0.00      0.00        25\n         101       0.99      1.00      0.99     13389\n         102       0.16      0.01      0.02       222\n         103       0.00      0.00      0.00        16\n         104       0.98      1.00      0.99     13346\n         105       0.25      0.01      0.01       131\n         106       0.00      0.00      0.00        16\n         107       0.99      1.00      0.99     13437\n         108       0.00      0.00      0.00        48\n         109       0.00      0.00      0.00         6\n         110       1.00      1.00      1.00     13530\n         111       0.00      0.00      0.00        51\n         112       0.00      0.00      0.00         6\n         113       1.00      1.00      1.00     13527\n\n   micro avg       0.98      0.98      0.98    516192\n   macro avg       0.39      0.34      0.34    516192\nweighted avg       0.97      0.98      0.98    516192\n samples avg       0.98      0.98      0.98    516192\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}